{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Classification ANN\n",
    "#### Developed a model to classify whether a tumor is malignant or benign based on various attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "92O3IE7jAPq8"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Urfd-ACEAWdu"
   },
   "outputs": [],
   "source": [
    "from  sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading and understanding the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9jq2QfuxAbYu"
   },
   "outputs": [],
   "source": [
    "data = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 871,
     "status": "ok",
     "timestamp": 1591736323974,
     "user": {
      "displayName": "Adarsh Pachori",
      "photoUrl": "",
      "userId": "06453457984377806328"
     },
     "user_tz": 420
    },
    "id": "RD_SnZqWAiAZ",
    "outputId": "0300988c-19c5-4988-e723-6d193d0b09da"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.utils.Bunch"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 903,
     "status": "ok",
     "timestamp": 1591736324362,
     "user": {
      "displayName": "Adarsh Pachori",
      "photoUrl": "",
      "userId": "06453457984377806328"
     },
     "user_tz": 420
    },
    "id": "wsMJzms_AkNm",
    "outputId": "60bf6a36-1b72-4d97-e7a7-9840e8b34736"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _breast_cancer_dataset:\n",
      "\n",
      "Breast cancer wisconsin (diagnostic) dataset\n",
      "--------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 569\n",
      "\n",
      "    :Number of Attributes: 30 numeric, predictive attributes and the class\n",
      "\n",
      "    :Attribute Information:\n",
      "        - radius (mean of distances from center to points on the perimeter)\n",
      "        - texture (standard deviation of gray-scale values)\n",
      "        - perimeter\n",
      "        - area\n",
      "        - smoothness (local variation in radius lengths)\n",
      "        - compactness (perimeter^2 / area - 1.0)\n",
      "        - concavity (severity of concave portions of the contour)\n",
      "        - concave points (number of concave portions of the contour)\n",
      "        - symmetry \n",
      "        - fractal dimension (\"coastline approximation\" - 1)\n",
      "\n",
      "        The mean, standard error, and \"worst\" or largest (mean of the three\n",
      "        largest values) of these features were computed for each image,\n",
      "        resulting in 30 features.  For instance, field 3 is Mean Radius, field\n",
      "        13 is Radius SE, field 23 is Worst Radius.\n",
      "\n",
      "        - class:\n",
      "                - WDBC-Malignant\n",
      "                - WDBC-Benign\n",
      "\n",
      "    :Summary Statistics:\n",
      "\n",
      "    ===================================== ====== ======\n",
      "                                           Min    Max\n",
      "    ===================================== ====== ======\n",
      "    radius (mean):                        6.981  28.11\n",
      "    texture (mean):                       9.71   39.28\n",
      "    perimeter (mean):                     43.79  188.5\n",
      "    area (mean):                          143.5  2501.0\n",
      "    smoothness (mean):                    0.053  0.163\n",
      "    compactness (mean):                   0.019  0.345\n",
      "    concavity (mean):                     0.0    0.427\n",
      "    concave points (mean):                0.0    0.201\n",
      "    symmetry (mean):                      0.106  0.304\n",
      "    fractal dimension (mean):             0.05   0.097\n",
      "    radius (standard error):              0.112  2.873\n",
      "    texture (standard error):             0.36   4.885\n",
      "    perimeter (standard error):           0.757  21.98\n",
      "    area (standard error):                6.802  542.2\n",
      "    smoothness (standard error):          0.002  0.031\n",
      "    compactness (standard error):         0.002  0.135\n",
      "    concavity (standard error):           0.0    0.396\n",
      "    concave points (standard error):      0.0    0.053\n",
      "    symmetry (standard error):            0.008  0.079\n",
      "    fractal dimension (standard error):   0.001  0.03\n",
      "    radius (worst):                       7.93   36.04\n",
      "    texture (worst):                      12.02  49.54\n",
      "    perimeter (worst):                    50.41  251.2\n",
      "    area (worst):                         185.2  4254.0\n",
      "    smoothness (worst):                   0.071  0.223\n",
      "    compactness (worst):                  0.027  1.058\n",
      "    concavity (worst):                    0.0    1.252\n",
      "    concave points (worst):               0.0    0.291\n",
      "    symmetry (worst):                     0.156  0.664\n",
      "    fractal dimension (worst):            0.055  0.208\n",
      "    ===================================== ====== ======\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Class Distribution: 212 - Malignant, 357 - Benign\n",
      "\n",
      "    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n",
      "\n",
      "    :Donor: Nick Street\n",
      "\n",
      "    :Date: November, 1995\n",
      "\n",
      "This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\n",
      "https://goo.gl/U2Uwz2\n",
      "\n",
      "Features are computed from a digitized image of a fine needle\n",
      "aspirate (FNA) of a breast mass.  They describe\n",
      "characteristics of the cell nuclei present in the image.\n",
      "\n",
      "Separating plane described above was obtained using\n",
      "Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
      "Construction Via Linear Programming.\" Proceedings of the 4th\n",
      "Midwest Artificial Intelligence and Cognitive Science Society,\n",
      "pp. 97-101, 1992], a classification method which uses linear\n",
      "programming to construct a decision tree.  Relevant features\n",
      "were selected using an exhaustive search in the space of 1-4\n",
      "features and 1-3 separating planes.\n",
      "\n",
      "The actual linear program used to obtain the separating plane\n",
      "in the 3-dimensional space is that described in:\n",
      "[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
      "Programming Discrimination of Two Linearly Inseparable Sets\",\n",
      "Optimization Methods and Software 1, 1992, 23-34].\n",
      "\n",
      "This database is also available through the UW CS ftp server:\n",
      "\n",
      "ftp ftp.cs.wisc.edu\n",
      "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n",
      "     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \n",
      "     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n",
      "     San Jose, CA, 1993.\n",
      "   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n",
      "     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n",
      "     July-August 1995.\n",
      "   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n",
      "     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n",
      "     163-171.\n"
     ]
    }
   ],
   "source": [
    "print(data.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 645,
     "status": "ok",
     "timestamp": 1591736325414,
     "user": {
      "displayName": "Adarsh Pachori",
      "photoUrl": "",
      "userId": "06453457984377806328"
     },
     "user_tz": 420
    },
    "id": "824J6CUIAnAO",
    "outputId": "9552cd34-b7b9-4502-ff5c-d0da55dc15ce"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['malignant', 'benign'], dtype='<U9')"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 261,
     "status": "ok",
     "timestamp": 1591736326235,
     "user": {
      "displayName": "Adarsh Pachori",
      "photoUrl": "",
      "userId": "06453457984377806328"
     },
     "user_tz": 420
    },
    "id": "iGgCD_xZA8c3",
    "outputId": "6deda341-bcee-4f0e-8964-82a85a5b7f77"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
       "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
       "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
       "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
       "       'smoothness error', 'compactness error', 'concavity error',\n",
       "       'concave points error', 'symmetry error',\n",
       "       'fractal dimension error', 'worst radius', 'worst texture',\n",
       "       'worst perimeter', 'worst area', 'worst smoothness',\n",
       "       'worst compactness', 'worst concavity', 'worst concave points',\n",
       "       'worst symmetry', 'worst fractal dimension'], dtype='<U23')"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 767,
     "status": "ok",
     "timestamp": 1591736327328,
     "user": {
      "displayName": "Adarsh Pachori",
      "photoUrl": "",
      "userId": "06453457984377806328"
     },
     "user_tz": 420
    },
    "id": "fxboLZtLA9it",
    "outputId": "8ae617aa-c93e-4cae-bcc2-82d4fe02f51d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
       "        1.189e-01],\n",
       "       [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
       "        8.902e-02],\n",
       "       [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
       "        8.758e-02],\n",
       "       ...,\n",
       "       [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
       "        7.820e-02],\n",
       "       [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
       "        1.240e-01],\n",
       "       [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
       "        7.039e-02]])"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WFmhvL8DA_aT"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t7T_hFnwBCWY"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8UiJV6SeCViQ"
   },
   "outputs": [],
   "source": [
    "df['target'] = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 725,
     "status": "ok",
     "timestamp": 1591736329107,
     "user": {
      "displayName": "Adarsh Pachori",
      "photoUrl": "",
      "userId": "06453457984377806328"
     },
     "user_tz": 420
    },
    "id": "v4OrExYXCcyx",
    "outputId": "3e99f0a6-66cc-4935-dfe0-eb8578c7aadd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>1.0950</td>\n",
       "      <td>0.9053</td>\n",
       "      <td>8.589</td>\n",
       "      <td>153.40</td>\n",
       "      <td>0.006399</td>\n",
       "      <td>0.04904</td>\n",
       "      <td>0.05373</td>\n",
       "      <td>0.01587</td>\n",
       "      <td>0.03003</td>\n",
       "      <td>0.006193</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>0.5435</td>\n",
       "      <td>0.7339</td>\n",
       "      <td>3.398</td>\n",
       "      <td>74.08</td>\n",
       "      <td>0.005225</td>\n",
       "      <td>0.01308</td>\n",
       "      <td>0.01860</td>\n",
       "      <td>0.01340</td>\n",
       "      <td>0.01389</td>\n",
       "      <td>0.003532</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>0.7456</td>\n",
       "      <td>0.7869</td>\n",
       "      <td>4.585</td>\n",
       "      <td>94.03</td>\n",
       "      <td>0.006150</td>\n",
       "      <td>0.04006</td>\n",
       "      <td>0.03832</td>\n",
       "      <td>0.02058</td>\n",
       "      <td>0.02250</td>\n",
       "      <td>0.004571</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>0.4956</td>\n",
       "      <td>1.1560</td>\n",
       "      <td>3.445</td>\n",
       "      <td>27.23</td>\n",
       "      <td>0.009110</td>\n",
       "      <td>0.07458</td>\n",
       "      <td>0.05661</td>\n",
       "      <td>0.01867</td>\n",
       "      <td>0.05963</td>\n",
       "      <td>0.009208</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>0.7572</td>\n",
       "      <td>0.7813</td>\n",
       "      <td>5.438</td>\n",
       "      <td>94.44</td>\n",
       "      <td>0.011490</td>\n",
       "      <td>0.02461</td>\n",
       "      <td>0.05688</td>\n",
       "      <td>0.01885</td>\n",
       "      <td>0.01756</td>\n",
       "      <td>0.005115</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>1.1760</td>\n",
       "      <td>1.2560</td>\n",
       "      <td>7.673</td>\n",
       "      <td>158.70</td>\n",
       "      <td>0.010300</td>\n",
       "      <td>0.02891</td>\n",
       "      <td>0.05198</td>\n",
       "      <td>0.02454</td>\n",
       "      <td>0.01114</td>\n",
       "      <td>0.004239</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>0.7655</td>\n",
       "      <td>2.4630</td>\n",
       "      <td>5.203</td>\n",
       "      <td>99.04</td>\n",
       "      <td>0.005769</td>\n",
       "      <td>0.02423</td>\n",
       "      <td>0.03950</td>\n",
       "      <td>0.01678</td>\n",
       "      <td>0.01898</td>\n",
       "      <td>0.002498</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>0.4564</td>\n",
       "      <td>1.0750</td>\n",
       "      <td>3.425</td>\n",
       "      <td>48.55</td>\n",
       "      <td>0.005903</td>\n",
       "      <td>0.03731</td>\n",
       "      <td>0.04730</td>\n",
       "      <td>0.01557</td>\n",
       "      <td>0.01318</td>\n",
       "      <td>0.003892</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>0.7260</td>\n",
       "      <td>1.5950</td>\n",
       "      <td>5.772</td>\n",
       "      <td>86.22</td>\n",
       "      <td>0.006522</td>\n",
       "      <td>0.06158</td>\n",
       "      <td>0.07117</td>\n",
       "      <td>0.01664</td>\n",
       "      <td>0.02324</td>\n",
       "      <td>0.006185</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>0.3857</td>\n",
       "      <td>1.4280</td>\n",
       "      <td>2.548</td>\n",
       "      <td>19.15</td>\n",
       "      <td>0.007189</td>\n",
       "      <td>0.00466</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.02676</td>\n",
       "      <td>0.002783</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0      1       2       3  ...      27      28       29  target\n",
       "0    17.99  10.38  122.80  1001.0  ...  0.2654  0.4601  0.11890       0\n",
       "1    20.57  17.77  132.90  1326.0  ...  0.1860  0.2750  0.08902       0\n",
       "2    19.69  21.25  130.00  1203.0  ...  0.2430  0.3613  0.08758       0\n",
       "3    11.42  20.38   77.58   386.1  ...  0.2575  0.6638  0.17300       0\n",
       "4    20.29  14.34  135.10  1297.0  ...  0.1625  0.2364  0.07678       0\n",
       "..     ...    ...     ...     ...  ...     ...     ...      ...     ...\n",
       "564  21.56  22.39  142.00  1479.0  ...  0.2216  0.2060  0.07115       0\n",
       "565  20.13  28.25  131.20  1261.0  ...  0.1628  0.2572  0.06637       0\n",
       "566  16.60  28.08  108.30   858.1  ...  0.1418  0.2218  0.07820       0\n",
       "567  20.60  29.33  140.10  1265.0  ...  0.2650  0.4087  0.12400       0\n",
       "568   7.76  24.54   47.92   181.0  ...  0.0000  0.2871  0.07039       1\n",
       "\n",
       "[569 rows x 31 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting the data into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NE44FL8QCeT0"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(df.drop(\"target\", axis = 1), df[\"target\"], test_size =0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 248,
     "status": "ok",
     "timestamp": 1591736330025,
     "user": {
      "displayName": "Adarsh Pachori",
      "photoUrl": "",
      "userId": "06453457984377806328"
     },
     "user_tz": 420
    },
    "id": "Q4ncwUeSCsuw",
    "outputId": "b9419e38-0925-4cbd-90a4-0881da3868b2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(381, 30)"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scaling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t2-c1effC0Fw"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zLHCzgCxD7CJ"
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5RMsOPz3Hgqr"
   },
   "outputs": [],
   "source": [
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building and training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uAPoUDSnHnhV"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "                                    tf.keras.layers.Input(shape=(30,)),\n",
    "                                    tf.keras.layers.Dense(1, activation = \"sigmoid\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "knzOVhn7IxUi"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss = \"binary_crossentropy\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6832,
     "status": "ok",
     "timestamp": 1591736347236,
     "user": {
      "displayName": "Adarsh Pachori",
      "photoUrl": "",
      "userId": "06453457984377806328"
     },
     "user_tz": 420
    },
    "id": "NyJay9XlJT2g",
    "outputId": "7d76f225-541a-42f4-98ef-dfdb9cad2421"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.5450 - accuracy: 0.7034 - val_loss: 0.6003 - val_accuracy: 0.6968\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4919 - accuracy: 0.7480 - val_loss: 0.5430 - val_accuracy: 0.7553\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4458 - accuracy: 0.8005 - val_loss: 0.4952 - val_accuracy: 0.7926\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4080 - accuracy: 0.8268 - val_loss: 0.4545 - val_accuracy: 0.8245\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.3756 - accuracy: 0.8635 - val_loss: 0.4202 - val_accuracy: 0.8511\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.3492 - accuracy: 0.8871 - val_loss: 0.3901 - val_accuracy: 0.8617\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3258 - accuracy: 0.9055 - val_loss: 0.3652 - val_accuracy: 0.8617\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.3064 - accuracy: 0.9186 - val_loss: 0.3431 - val_accuracy: 0.8617\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2893 - accuracy: 0.9186 - val_loss: 0.3243 - val_accuracy: 0.8777\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2743 - accuracy: 0.9318 - val_loss: 0.3078 - val_accuracy: 0.8936\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2612 - accuracy: 0.9318 - val_loss: 0.2931 - val_accuracy: 0.8989\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2499 - accuracy: 0.9344 - val_loss: 0.2797 - val_accuracy: 0.9043\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2394 - accuracy: 0.9344 - val_loss: 0.2682 - val_accuracy: 0.9149\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2302 - accuracy: 0.9396 - val_loss: 0.2575 - val_accuracy: 0.9149\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.2219 - accuracy: 0.9475 - val_loss: 0.2479 - val_accuracy: 0.9149\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2142 - accuracy: 0.9501 - val_loss: 0.2393 - val_accuracy: 0.9149\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2074 - accuracy: 0.9501 - val_loss: 0.2313 - val_accuracy: 0.9149\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2009 - accuracy: 0.9501 - val_loss: 0.2242 - val_accuracy: 0.9149\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1954 - accuracy: 0.9501 - val_loss: 0.2172 - val_accuracy: 0.9149\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1899 - accuracy: 0.9501 - val_loss: 0.2110 - val_accuracy: 0.9149\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1849 - accuracy: 0.9501 - val_loss: 0.2052 - val_accuracy: 0.9149\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1803 - accuracy: 0.9501 - val_loss: 0.2001 - val_accuracy: 0.9149\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1761 - accuracy: 0.9501 - val_loss: 0.1950 - val_accuracy: 0.9149\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1720 - accuracy: 0.9501 - val_loss: 0.1904 - val_accuracy: 0.9149\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.1683 - accuracy: 0.9501 - val_loss: 0.1861 - val_accuracy: 0.9202\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1648 - accuracy: 0.9528 - val_loss: 0.1820 - val_accuracy: 0.9202\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1614 - accuracy: 0.9528 - val_loss: 0.1783 - val_accuracy: 0.9255\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1583 - accuracy: 0.9528 - val_loss: 0.1748 - val_accuracy: 0.9309\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1554 - accuracy: 0.9528 - val_loss: 0.1714 - val_accuracy: 0.9362\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1526 - accuracy: 0.9528 - val_loss: 0.1682 - val_accuracy: 0.9415\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1499 - accuracy: 0.9528 - val_loss: 0.1652 - val_accuracy: 0.9415\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1474 - accuracy: 0.9554 - val_loss: 0.1624 - val_accuracy: 0.9415\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.1450 - accuracy: 0.9554 - val_loss: 0.1598 - val_accuracy: 0.9468\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.1428 - accuracy: 0.9606 - val_loss: 0.1572 - val_accuracy: 0.9521\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1406 - accuracy: 0.9633 - val_loss: 0.1548 - val_accuracy: 0.9521\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1385 - accuracy: 0.9633 - val_loss: 0.1526 - val_accuracy: 0.9521\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1365 - accuracy: 0.9633 - val_loss: 0.1504 - val_accuracy: 0.9521\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.1347 - accuracy: 0.9633 - val_loss: 0.1482 - val_accuracy: 0.9521\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.1328 - accuracy: 0.9633 - val_loss: 0.1463 - val_accuracy: 0.9521\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1311 - accuracy: 0.9633 - val_loss: 0.1445 - val_accuracy: 0.9468\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1294 - accuracy: 0.9633 - val_loss: 0.1428 - val_accuracy: 0.9468\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1279 - accuracy: 0.9633 - val_loss: 0.1410 - val_accuracy: 0.9468\n",
      "Epoch 43/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.1263 - accuracy: 0.9633 - val_loss: 0.1395 - val_accuracy: 0.9468\n",
      "Epoch 44/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1248 - accuracy: 0.9633 - val_loss: 0.1379 - val_accuracy: 0.9468\n",
      "Epoch 45/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1234 - accuracy: 0.9659 - val_loss: 0.1364 - val_accuracy: 0.9468\n",
      "Epoch 46/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1220 - accuracy: 0.9659 - val_loss: 0.1350 - val_accuracy: 0.9468\n",
      "Epoch 47/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1207 - accuracy: 0.9659 - val_loss: 0.1337 - val_accuracy: 0.9468\n",
      "Epoch 48/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1194 - accuracy: 0.9659 - val_loss: 0.1323 - val_accuracy: 0.9468\n",
      "Epoch 49/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1182 - accuracy: 0.9659 - val_loss: 0.1311 - val_accuracy: 0.9468\n",
      "Epoch 50/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1170 - accuracy: 0.9659 - val_loss: 0.1297 - val_accuracy: 0.9468\n",
      "Epoch 51/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1158 - accuracy: 0.9659 - val_loss: 0.1285 - val_accuracy: 0.9468\n",
      "Epoch 52/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.1147 - accuracy: 0.9659 - val_loss: 0.1274 - val_accuracy: 0.9521\n",
      "Epoch 53/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.1136 - accuracy: 0.9659 - val_loss: 0.1263 - val_accuracy: 0.9574\n",
      "Epoch 54/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1125 - accuracy: 0.9659 - val_loss: 0.1253 - val_accuracy: 0.9574\n",
      "Epoch 55/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1115 - accuracy: 0.9685 - val_loss: 0.1243 - val_accuracy: 0.9574\n",
      "Epoch 56/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1105 - accuracy: 0.9685 - val_loss: 0.1233 - val_accuracy: 0.9574\n",
      "Epoch 57/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1096 - accuracy: 0.9685 - val_loss: 0.1224 - val_accuracy: 0.9574\n",
      "Epoch 58/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1086 - accuracy: 0.9685 - val_loss: 0.1214 - val_accuracy: 0.9574\n",
      "Epoch 59/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1077 - accuracy: 0.9685 - val_loss: 0.1205 - val_accuracy: 0.9574\n",
      "Epoch 60/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.1068 - accuracy: 0.9711 - val_loss: 0.1197 - val_accuracy: 0.9574\n",
      "Epoch 61/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1060 - accuracy: 0.9711 - val_loss: 0.1188 - val_accuracy: 0.9628\n",
      "Epoch 62/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.1051 - accuracy: 0.9711 - val_loss: 0.1179 - val_accuracy: 0.9628\n",
      "Epoch 63/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1043 - accuracy: 0.9711 - val_loss: 0.1171 - val_accuracy: 0.9628\n",
      "Epoch 64/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1035 - accuracy: 0.9711 - val_loss: 0.1163 - val_accuracy: 0.9628\n",
      "Epoch 65/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1027 - accuracy: 0.9711 - val_loss: 0.1156 - val_accuracy: 0.9628\n",
      "Epoch 66/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1020 - accuracy: 0.9711 - val_loss: 0.1149 - val_accuracy: 0.9628\n",
      "Epoch 67/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1012 - accuracy: 0.9738 - val_loss: 0.1141 - val_accuracy: 0.9628\n",
      "Epoch 68/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1005 - accuracy: 0.9738 - val_loss: 0.1135 - val_accuracy: 0.9628\n",
      "Epoch 69/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0998 - accuracy: 0.9764 - val_loss: 0.1129 - val_accuracy: 0.9628\n",
      "Epoch 70/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0991 - accuracy: 0.9764 - val_loss: 0.1122 - val_accuracy: 0.9681\n",
      "Epoch 71/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0984 - accuracy: 0.9764 - val_loss: 0.1116 - val_accuracy: 0.9681\n",
      "Epoch 72/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0978 - accuracy: 0.9764 - val_loss: 0.1110 - val_accuracy: 0.9681\n",
      "Epoch 73/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0971 - accuracy: 0.9764 - val_loss: 0.1104 - val_accuracy: 0.9681\n",
      "Epoch 74/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0965 - accuracy: 0.9764 - val_loss: 0.1098 - val_accuracy: 0.9681\n",
      "Epoch 75/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0959 - accuracy: 0.9764 - val_loss: 0.1092 - val_accuracy: 0.9681\n",
      "Epoch 76/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0953 - accuracy: 0.9764 - val_loss: 0.1086 - val_accuracy: 0.9681\n",
      "Epoch 77/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0947 - accuracy: 0.9764 - val_loss: 0.1082 - val_accuracy: 0.9681\n",
      "Epoch 78/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0941 - accuracy: 0.9764 - val_loss: 0.1076 - val_accuracy: 0.9681\n",
      "Epoch 79/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0936 - accuracy: 0.9764 - val_loss: 0.1072 - val_accuracy: 0.9734\n",
      "Epoch 80/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0930 - accuracy: 0.9764 - val_loss: 0.1067 - val_accuracy: 0.9734\n",
      "Epoch 81/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0925 - accuracy: 0.9764 - val_loss: 0.1062 - val_accuracy: 0.9734\n",
      "Epoch 82/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0919 - accuracy: 0.9816 - val_loss: 0.1057 - val_accuracy: 0.9734\n",
      "Epoch 83/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0914 - accuracy: 0.9816 - val_loss: 0.1052 - val_accuracy: 0.9734\n",
      "Epoch 84/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0909 - accuracy: 0.9816 - val_loss: 0.1047 - val_accuracy: 0.9734\n",
      "Epoch 85/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0904 - accuracy: 0.9816 - val_loss: 0.1042 - val_accuracy: 0.9734\n",
      "Epoch 86/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0899 - accuracy: 0.9816 - val_loss: 0.1038 - val_accuracy: 0.9734\n",
      "Epoch 87/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0894 - accuracy: 0.9816 - val_loss: 0.1034 - val_accuracy: 0.9734\n",
      "Epoch 88/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0890 - accuracy: 0.9816 - val_loss: 0.1031 - val_accuracy: 0.9734\n",
      "Epoch 89/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0885 - accuracy: 0.9816 - val_loss: 0.1027 - val_accuracy: 0.9734\n",
      "Epoch 90/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0881 - accuracy: 0.9816 - val_loss: 0.1022 - val_accuracy: 0.9734\n",
      "Epoch 91/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0876 - accuracy: 0.9816 - val_loss: 0.1018 - val_accuracy: 0.9734\n",
      "Epoch 92/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0872 - accuracy: 0.9816 - val_loss: 0.1015 - val_accuracy: 0.9734\n",
      "Epoch 93/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0867 - accuracy: 0.9816 - val_loss: 0.1011 - val_accuracy: 0.9734\n",
      "Epoch 94/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0864 - accuracy: 0.9816 - val_loss: 0.1007 - val_accuracy: 0.9734\n",
      "Epoch 95/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0859 - accuracy: 0.9816 - val_loss: 0.1003 - val_accuracy: 0.9734\n",
      "Epoch 96/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0855 - accuracy: 0.9816 - val_loss: 0.1000 - val_accuracy: 0.9734\n",
      "Epoch 97/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0851 - accuracy: 0.9816 - val_loss: 0.0997 - val_accuracy: 0.9734\n",
      "Epoch 98/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0847 - accuracy: 0.9816 - val_loss: 0.0994 - val_accuracy: 0.9734\n",
      "Epoch 99/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0843 - accuracy: 0.9816 - val_loss: 0.0989 - val_accuracy: 0.9734\n",
      "Epoch 100/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0839 - accuracy: 0.9816 - val_loss: 0.0986 - val_accuracy: 0.9734\n"
     ]
    }
   ],
   "source": [
    "r = model.fit(x_train, y_train, validation_data = (x_test, y_test), epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PQCZOs3cKBja"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3377,
     "status": "ok",
     "timestamp": 1591736347549,
     "user": {
      "displayName": "Adarsh Pachori",
      "photoUrl": "",
      "userId": "06453457984377806328"
     },
     "user_tz": 420
    },
    "id": "ZhT3y6AkKZI7",
    "outputId": "4ad7432a-8cfd-433c-c46e-34d3c6966460"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fcf57f940b8>"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(r.history['loss'],label = \"loss\")\n",
    "plt.plot(r.history['val_loss'], label = \"val_loss\")\n",
    "print(r.history.keys())\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J4kCkxWxKn0W"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 384,
     "status": "ok",
     "timestamp": 1591736458842,
     "user": {
      "displayName": "Adarsh Pachori",
      "photoUrl": "",
      "userId": "06453457984377806328"
     },
     "user_tz": 420
    },
    "id": "yjER3Pwf4Gow",
    "outputId": "eaedab6b-5e0e-42e8-c9df-5def4f846cae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96        69\n",
      "           1       0.96      1.00      0.98       119\n",
      "\n",
      "    accuracy                           0.97       188\n",
      "   macro avg       0.98      0.96      0.97       188\n",
      "weighted avg       0.97      0.97      0.97       188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, model.predict_classes(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 396,
     "status": "ok",
     "timestamp": 1591736460782,
     "user": {
      "displayName": "Adarsh Pachori",
      "photoUrl": "",
      "userId": "06453457984377806328"
     },
     "user_tz": 420
    },
    "id": "XAHcJmg94ISr",
    "outputId": "fe59fe2a-159a-409b-b4b8-b6a9440e9917"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 64   5]\n",
      " [  0 119]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, model.predict_classes(x_test)))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOXJzL1KkTHk0/ofwK71Ipu",
   "name": "LinearClassificationTF.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
